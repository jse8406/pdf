
import streamlit as st
import pdfplumber
import difflib
import re

# -----------------------------------------------------------------------------
# 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (Normalization)
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
# 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (Normalization)
# -----------------------------------------------------------------------------
def normalize_text(text):
    if not text:
        return ""

    # 0. ë…¸ì´ì¦ˆ ì œê±° (ë°˜ë³µë˜ëŠ” ì›¹ì‚¬ì´íŠ¸ UI í…ìŠ¤íŠ¸, URL, ì‹œê°„ ë“±)
    text = re.sub(r'(PDF|XML|HTML)\s*ë‹¤ìš´ë¡œë“œ', '', text, flags=re.IGNORECASE)
    text = re.sub(r'ë³€ê²½\s*ì´ë ¥', '', text)
    text = re.sub(r'https?://\S+', '', text)
    text = re.sub(r'\d{2,4}[. ]+\d{1,2}[. ]+\d{1,2}[.]?', '', text) 
    text = re.sub(r'(ì˜¤ì „|ì˜¤í›„)\s*\d{1,2}\s*[:]\s*\d{2}(?:\s*[:]\s*\d{2})?', '', text) 
    text = re.sub(r'\b\d+\s*/\s*\d+\b', '', text) 
    text = re.sub(r'cacheSeq=[a-zA-Z0-9]+', '', text)
    
    # 1. ìŠ¤ë§ˆíŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (Smart Reflow)
    #    ë¬´ì¡°ê±´ ì¤„ë°”ê¿ˆì„ ì—†ì• ë©´ ëª©ë¡ì´ë‚˜ ë¬¸ë‹¨ì´ ë­‰ê°œì§€ë¯€ë¡œ, "ì˜ë¯¸ ìˆëŠ” ì¤„ë°”ê¿ˆ"ì€ ì‚´ë¦½ë‹ˆë‹¤.
    #    (1) ë¬¸ì¥ì´ ëë‚˜ëŠ” ëŠë‚Œ(. : ) ë’¤ì˜ ì¤„ë°”ê¿ˆ -> ìœ ì§€ (\n)
    #    (2) ëª©ë¡ ê¸°í˜¸(â€¢, -, ìˆ«ì.) ì•ì˜ ì¤„ë°”ê¿ˆ -> ìœ ì§€ (\n)
    #    (3) ê·¸ ì™¸ ì–´ì •ì©¡í•œ ì¤„ë°”ê¿ˆ -> ê³µë°±(' ')ìœ¼ë¡œ ì¹˜í™˜ (Soft Wrap ì²˜ë¦¬)
    
    # ì •ê·œì‹ íŒ¨í„´: ì¤„ë°”ê¿ˆ ë’¤ì— "ëª©ë¡ ê¸°í˜¸"ê°€ ì˜¤ê±°ë‚˜, "ë¬¸ì¥ ë¶€í˜¸" ë’¤ì— ì¤„ë°”ê¿ˆì´ ìˆëŠ” ê²½ìš°ë¥¼ ì œì™¸í•˜ê³  ê³µë°±í™”
    # ëª©ë¡ ê¸°í˜¸: â€¢, -, *, ìˆ«ì. (1. 2. ë“±)
    # ë¬¸ì¥ ë¶€í˜¸: ., :, ], )
    
    def smart_join(match):
        prev_char = match.string[match.start()-1] # ì¤„ë°”ê¿ˆ ì•ê¸€ì
        next_chunk = match.string[match.end()] if match.end() < len(match.string) else "" # ì¤„ë°”ê¿ˆ ë’·ê¸€ì

        # Hard Wrap ì¡°ê±´ 1: ë¬¸ì¥ ì¢…ë£Œ ë¶€í˜¸ ë’¤
        if prev_char in ['.', ':', ']', ')', '>', '!', '?']:
            return '\n'
        
        # Hard Wrap ì¡°ê±´ 2: ëª©ë¡ ê¸°í˜¸ ì• ( â€¢, -, ìˆ«ì.)
        if next_chunk in ['â€¢', '-', '*', '[']:
            return '\n'
        # ìˆ«ì + ì  (ì˜ˆ: 1. ) íŒ¨í„´ í™•ì¸ì€ ì—¬ê¸°ì„œ ì–´ë µì§€ë§Œ, ì¼ë‹¨ ë‹¨ìˆœ ê¸°í˜¸ë§Œ ì²´í¬
        
        # ê·¸ ì™¸ì—ëŠ” Soft Wrapìœ¼ë¡œ ê°„ì£¼í•˜ê³  Join
        return ' '

    # ì¤„ë°”ê¿ˆ(\n)ì„ ì°¾ì•„ì„œ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ì²˜ë¦¬
    # (ì£¼ì˜: \nì´ ì—¬ëŸ¬ê°œë©´ í•˜ë‚˜ë¡œ ì·¨ê¸‰í•˜ê¸° ìœ„í•´ re.sub ì‚¬ìš©)
    text = re.sub(r'(?<!\n)\n(?!\n)', smart_join, text)
    
    # 2. íƒ­ ì œê±°
    text = text.replace('\t', ' ')

    # 3. íŠ¹ìˆ˜ë¬¸ì ì œê±° (ê°€ë…ì„±ì„ í•´ì¹˜ì§€ ì•ŠëŠ” ì„ ì—ì„œ)
    #    ë‹¨, ì¤„ë°”ê¿ˆ ë³´ì¡´ì„ ìœ„í•´ \nì€ ì‚´ë ¤ì•¼ í•¨.
    #    â€¢, - ê°™ì€ ëª©ë¡ ê¸°í˜¸ë„ êµ¬ì¡° íŒŒì•…ì„ ìœ„í•´ ì‚´ë ¤ë‘ëŠ” ê²ƒì´ ì¢‹ìŒ.
    text = re.sub(r'[,\'"`]', ' ', text) # ì½¤ë§ˆ, ë”°ì˜´í‘œ ë“± ì•„ì£¼ ì‚¬ì†Œí•œ ê²ƒë§Œ ì œê±°
    
    # ê´„í˜¸ ë“±ì€ êµ¬ì¡°ìƒ ì¤‘ìš”í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìœ ì§€í•˜ë˜, ì§€ë‚˜ì¹œ ê¸°í˜¸ë§Œ ì •ë¦¬
    # (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì¡°ì ˆ ê°€ëŠ¥)

    # 4. í•œêµ­ì–´ ì–´ë¯¸/ì¡°ì‚¬ ì™„í™”
    text = re.sub(r'(í–ˆ|ì˜€|ì•˜|ì—ˆ|ê² )?(ìŠµë‹ˆ|ì˜µë‹ˆ|ë¹„ë‹ˆ)?ë‹¤\b', r'\1ë‹¤', text)
    text = re.sub(r'ì…ë‹ˆë‹¤\b', 'ì´ë‹¤', text)
    
    # 5. ê³µë°± ì •ê·œí™” (ì—°ì†ëœ ê³µë°± í•˜ë‚˜ë¡œ, ë‹¨ \nì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
    text = re.sub(r'[ \t]+', ' ', text).strip()
    # \n ì£¼ìœ„ì˜ ê³µë°± ì •ë¦¬
    text = re.sub(r' *\n *', '\n', text)
    
    return text

# -----------------------------------------------------------------------------
# 2. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìŠ¤ë§ˆíŠ¸ ì„¹ì…˜ í•„í„°ë§)
# -----------------------------------------------------------------------------
def extract_target_sections(full_text):
    """
    ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ 'íš¨ëŠ¥Â·íš¨ê³¼', 'ìš©ë²•Â·ìš©ëŸ‰', 'ì‚¬ìš©ìƒì˜ ì£¼ì˜ì‚¬í•­' ì„¹ì…˜ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ê´„í˜¸ê°€ ì—†ëŠ” í—¤ë”(ì˜ˆ: 'ìš©ë²•ìš©ëŸ‰')ë„ ìœ ì—°í•˜ê²Œ ì¸ì‹í•˜ë©°, 
    'ì„±ìƒ', 'ì €ì¥ë°©ë²•' ë“± ë¶ˆí•„ìš”í•œ ì„¹ì…˜ì´ ë‚˜ì˜¤ë©´ ì¶”ì¶œì„ ë©ˆì¶¥ë‹ˆë‹¤.
    """
    
    # 1. ì„¹ì…˜ í—¤ë”ë¡œ ì˜ì‹¬ë˜ëŠ” ëª¨ë“  ë¼ì¸ì„ ì°¾ìŠµë‹ˆë‹¤.
    keyword_pattern = r"(?:íš¨\s*ëŠ¥|íš¨\s*ê³¼|ìš©\s*ë²•|ìš©\s*ëŸ‰|íˆ¬\s*ì—¬|ì£¼\s*ì˜\s*ì‚¬\s*í•­|ê²½\s*ê³ |ì„±\s*ìƒ|ì €\s*ì¥|ë³´\s*ê´€|ê¸°\s*ê°„|ì›\s*ë£Œ|ì œ\s*ì¡°|í¬\s*ì¥|êµ¬\s*ì„±)"
    header_regex = r"(?m)^[\s\d\.\â€¢\[ã€\|Â·\-]*(?:" + keyword_pattern + r")[^\n]{0,50}$"
    
    matches = []
    for match in re.finditer(header_regex, full_text):
        matches.append({
            "start": match.start(),
            "end": match.end(),
            "text": match.group(0).strip()
        })
    
    if not matches:
        return ""
        
    extracted_parts = []
    
    target_groups = {
        "íš¨ëŠ¥": ["íš¨ëŠ¥", "íš¨ê³¼"],
        "ìš©ë²•": ["ìš©ë²•", "ìš©ëŸ‰", "íˆ¬ì—¬"],
        "ì£¼ì˜": ["ì£¼ì˜", "ê²½ê³ ", "í™˜ì"]
    }
    
    for i, header in enumerate(matches):
        clean_title = re.sub(r'[\s\[\]ã€ã€‘\.\d\â€¢]', '', header['text'])
        
        is_target = False
        for key, text_list in target_groups.items():
            for t in text_list:
                if t in clean_title:
                    is_target = True
                    break
            if is_target: break
            
        if is_target:
            start_pos = header['end']
            if i < len(matches) - 1:
                end_pos = matches[i+1]['start']
            else:
                end_pos = len(full_text)
                
            content = full_text[start_pos:end_pos].strip()
            
            if len(content) < 2:
                continue
                
            extracted_parts.append(f"\n\n--- [{header['text']}] ---\n{content}")
            
    result = "".join(extracted_parts)
    return result if result else ""

def extract_text_from_pdf(file_obj):
    text = ""
    try:
        file_obj.seek(0)
        with pdfplumber.open(file_obj) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text(x_tolerance=2, y_tolerance=3)
                if page_text:
                    text += page_text + "\n"
        
        relevant_text = extract_target_sections(text)
        return relevant_text

    except Exception as e:
        return ""

# -----------------------------------------------------------------------------
# 3. Diff ê³„ì‚° (í…ìŠ¤íŠ¸ ë¹„êµ)
# -----------------------------------------------------------------------------
def compare_texts(text1, text2):
    # ì „ì²˜ë¦¬
    norm1 = normalize_text(text1)
    norm2 = normalize_text(text2)
    
    # í† í°í™” (ë‹¨ì–´ ë‹¨ìœ„ + ì¤„ë°”ê¿ˆ ë‹¨ìœ„)
    # \nì„ í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ì·¨ê¸‰í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    tokens1 = re.findall(r'\S+|\n', norm1)
    tokens2 = re.findall(r'\S+|\n', norm2)
    
    matcher = difflib.SequenceMatcher(None, tokens1, tokens2)
    
    diff_html_parts = []
    
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == 'equal':
            # ë³€ê²½ ì—†ëŠ” ë¶€ë¶„
            chunk = tokens1[i1:i2]
            # \nì„ <br>ë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥
            text_chunk = " ".join(chunk).replace('\n', '<br>')
            # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° (<br> ì•ë’¤)
            text_chunk = text_chunk.replace(' <br> ', '<br>').replace('<br> ', '<br>')
            diff_html_parts.append(f'<span style="color: #333;">{text_chunk}</span>')
            
        elif tag == 'replace':
            # ë³€ê²½: ì‚­ì œëœ ë¶€ë¶„(ë¹¨ê°•) -> ì¶”ê°€ëœ ë¶€ë¶„(ì´ˆë¡)
            
            # 1. ì‚­ì œëœ í…ìŠ¤íŠ¸
            del_chunk = tokens1[i1:i2]
            del_text = " ".join(del_chunk).replace('\n', 'â†µ<br>') # ì¤„ë°”ê¿ˆ ì‚­ì œ í‘œì‹œ
            diff_html_parts.append(f'<span style="background-color: #ffeef0; color: #b31d28; text-decoration: line-through; padding: 2px 0;">{del_text}</span>')
            
            diff_html_parts.append('<span style="color: #ccc; margin: 0 4px;">â–¶</span>')
            
            # 2. ì¶”ê°€ëœ í…ìŠ¤íŠ¸
            ins_chunk = tokens2[j1:j2]
            ins_text = " ".join(ins_chunk).replace('\n', 'â†µ<br>') # ì¤„ë°”ê¿ˆ ì¶”ê°€ í‘œì‹œ
            diff_html_parts.append(f'<span style="background-color: #e6ffed; color: #22863a; fontWeight: bold; padding: 2px 0;">{ins_text}</span>')
            
        elif tag == 'delete':
            del_chunk = tokens1[i1:i2]
            del_text = " ".join(del_chunk).replace('\n', 'â†µ<br>')
            diff_html_parts.append(f'<span style="background-color: #ffeef0; color: #b31d28; text-decoration: line-through; padding: 2px 0;">{del_text}</span>')
            
        elif tag == 'insert':
            ins_chunk = tokens2[j1:j2]
            ins_text = " ".join(ins_chunk).replace('\n', 'â†µ<br>')
            diff_html_parts.append(f'<span style="background-color: #e6ffed; color: #22863a; fontWeight: bold; padding: 2px 0;">{ins_text}</span>')
            
        # ê°€ë…ì„±ì„ ìœ„í•œ ê³µë°±
        diff_html_parts.append(" ")
        
    final_html = "".join(diff_html_parts)
    
    # HTML ê°€ë…ì„± ë³´ì • (ì—°ì†ëœ br ì •ë¦¬)
    final_html = final_html.replace(' <br>', '<br>').replace('<br> ', '<br>')
    
    return f'<div style="line-height: 1.8; font-size: 16px;">{final_html}</div>'

# -----------------------------------------------------------------------------
# 4. Main UI
# -----------------------------------------------------------------------------
def main():
    st.set_page_config(page_title="ìŠ¤ë§ˆíŠ¸ PDF ë¬¸ì„œ ë¹„êµê¸°", layout="wide")
    
    st.title("ğŸ“„ ìŠ¤ë§ˆíŠ¸ PDF ë¬¸ì„œ ë¹„êµê¸° (Text Ver.)")
    st.markdown("""
    ë‘ ê°œì˜ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´, ì„œì‹ì´ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì¡°ì‚¬('ìŠµë‹ˆë‹¤' ë“±) ì°¨ì´ëŠ” ë¬´ì‹œí•˜ê³  
    **íš¨ëŠ¥Â·íš¨ê³¼, ìš©ë²•Â·ìš©ëŸ‰, ì‚¬ìš©ìƒì˜ ì£¼ì˜ì‚¬í•­** ë“± í•µì‹¬ ë‚´ìš©ì˜ ë³€ê²½ì‚¬í•­ë§Œ í…ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        file1 = st.file_uploader("ì´ì „ ë²„ì „ íŒŒì¼ (PDF)", type=["pdf"], key="file1")
        
    with col2:
        file2 = st.file_uploader("ìƒˆë¡œìš´ ë²„ì „ íŒŒì¼ (PDF)", type=["pdf"], key="file2")
        
    if file1 and file2:
        with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ë¹„êµí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text1 = extract_text_from_pdf(file1)
            text2 = extract_text_from_pdf(file2)
            
            # [ë””ë²„ê¹…] ì¶”ì¶œ ë‚´ìš© í™•ì¸
            with st.expander("ğŸ” [ë””ë²„ê·¸] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í™•ì¸ (ì„¹ì…˜ì´ ì˜ ì¡í˜”ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”)"):
                d_col1, d_col2 = st.columns(2)
                d_col1.text_area("File 1 Extracted", text1, height=200)
                d_col2.text_area("File 2 Extracted", text2, height=200)

            # 2. ë¹„êµ ìˆ˜í–‰
            if not text1.strip() or not text2.strip():
                st.warning("âš ï¸ ë¬¸ì„œì—ì„œ ë¹„êµí•  í•µì‹¬ ì„¹ì…˜(íš¨ëŠ¥, ìš©ë²•, ì£¼ì˜ì‚¬í•­)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                st.info("ë¬¸ì„œê°€ ì´ë¯¸ì§€ í˜•íƒœì´ê±°ë‚˜, í•´ë‹¹ ì„¹ì…˜ ì œëª©ì´ ì¸ì‹ë˜ì§€ ì•ŠëŠ” íŠ¹ì´í•œ í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                diff_result = compare_texts(text1, text2)
                
                st.divider()
                st.subheader("ğŸ“Š ë¹„êµ ê²°ê³¼")
                
                if diff_result:
                    # ê²°ê³¼ ì¶œë ¥
                    st.markdown(diff_result, unsafe_allow_html=True)
                else:
                    st.success("âœ… ë‘ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©(íš¨ëŠ¥, ìš©ë²•, ì£¼ì˜ì‚¬í•­)ì´ ë™ì¼í•©ë‹ˆë‹¤.")
                    st.write("(ë‹¨ìˆœ ì¤„ë°”ê¿ˆì´ë‚˜, ì˜ë¯¸ ì—†ëŠ” ì¡°ì‚¬ëŠ” ë¬´ì‹œë˜ì—ˆìŠµë‹ˆë‹¤.)")

if __name__ == "__main__":
    main()
